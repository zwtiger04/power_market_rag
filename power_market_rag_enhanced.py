"""
Enhanced ì „ë ¥ì‹œì¥ RAG ì‹œìŠ¤í…œ ë©”ì¸ ëª¨ë“ˆ
- ê³ ë„í™”ëœ ë©”íƒ€ë°ì´í„°ì™€ ë²¡í„° ì—”ì§„ í™œìš©
- ì „ë ¥ì‹œì¥ íŠ¹í™” ì—°ê´€ì„± ë§¤í•‘
- AIê°€ ìµœëŒ€í•œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°í™”ëœ ì •ë³´ ì œê³µ
"""

import logging
import os
import yaml
from typing import List, Dict, Optional, Any
from pathlib import Path
from datetime import datetime

# ê° ëª¨ë“ˆ ì„í¬íŠ¸
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Enhanced ëª¨ë“ˆë“¤
from core.enhanced_vector_engine import EnhancedVectorEngine
from core.multimodal_processor import MultimodalProcessor
from core.document_hierarchy_analyzer import DocumentHierarchyAnalyzer
from core.relationship_mapper import PowerMarketRelationshipMapper
from embeddings.text_embedder import PowerMarketEmbedder
from generation.answer_generator import PowerMarketAnswerGenerator


class EnhancedPowerMarketRAG:
    """
    Enhanced ì „ë ¥ì‹œì¥ RAG ì‹œìŠ¤í…œ
    - ê³ ë„í™”ëœ ë©”íƒ€ë°ì´í„° í™œìš©
    - êµ¬ì¡°ì  ê³„ì¸µ ì •ë³´ ê¸°ë°˜ ê²€ìƒ‰
    - ì—°ê´€ì„± ë§¤í•‘ì„ í†µí•œ ë§¥ë½ì  ë‹µë³€
    - AI ì¹œí™”ì  ì •ë³´ êµ¬ì¡°í™”
    """
    
    def __init__(self, config_path: str = None):
        """
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.logger = logging.getLogger(__name__)
        
        # ì„¤ì • ë¡œë“œ
        self.config = self._load_config(config_path)
        
        # êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™” í”Œë˜ê·¸
        self.is_initialized = False
        
        # Enhanced êµ¬ì„± ìš”ì†Œë“¤
        self.multimodal_processor = None
        self.enhanced_vector_engine = None
        self.hierarchy_analyzer = None
        self.relationship_mapper = None
        self.embedder = None
        self.answer_generator = None
        
        self.logger.info("Enhanced PowerMarketRAG ì‹œìŠ¤í…œì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    def _load_config(self, config_path: str = None) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        if config_path is None:
            config_path = "config/config.yaml"
        
        default_config = {
            "VECTOR_DB_TYPE": "chromadb",
            "VECTOR_DB_PATH": "./vector_db",
            "COLLECTION_NAME": "power_market_docs_enhanced",
            "EMBEDDING_MODEL": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
            "EMBEDDING_DIMENSION": 768,
            "CHUNK_SIZE": 1000,
            "CHUNK_OVERLAP": 200,
            "TOP_K": 5,
            "SIMILARITY_THRESHOLD": 0.7,
            "API_HOST": "0.0.0.0",
            "API_PORT": 8000,
            "LOG_LEVEL": "INFO"
        }
        
        try:
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    file_config = yaml.safe_load(f)
                default_config.update(file_config)
                self.logger.info(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config_path}")
            else:
                self.logger.warning(f"ì„¤ì • íŒŒì¼ì´ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©: {config_path}")
        except Exception as e:
            self.logger.error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
        
        return default_config
    
    def initialize(self) -> bool:
        """ëª¨ë“  êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”"""
        try:
            self.logger.info("Enhanced RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘")
            
            # 1. Multimodal Processor
            self.logger.info("Multimodal Processor ì´ˆê¸°í™” ì¤‘...")
            self.multimodal_processor = MultimodalProcessor()
            
            # 2. Enhanced Vector Engine
            self.logger.info("Enhanced Vector Engine ì´ˆê¸°í™” ì¤‘...")
            self.enhanced_vector_engine = EnhancedVectorEngine(self.config)
            
            # 3. Document Hierarchy Analyzer
            self.logger.info("Document Hierarchy Analyzer ì´ˆê¸°í™” ì¤‘...")
            self.hierarchy_analyzer = DocumentHierarchyAnalyzer()
            
            # 4. Power Market Embedder
            self.logger.info("ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
            self.embedder = PowerMarketEmbedder(
                model_name=self.config["EMBEDDING_MODEL"]
            )
            
            # 5. Relationship Mapper
            self.logger.info("Relationship Mapper ì´ˆê¸°í™” ì¤‘...")
            self.relationship_mapper = PowerMarketRelationshipMapper(self.embedder)
            
            # 6. Answer Generator
            self.logger.info("Answer Generator ì´ˆê¸°í™” ì¤‘...")
            self.answer_generator = PowerMarketAnswerGenerator()
            
            self.is_initialized = True
            self.logger.info("Enhanced RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"Enhanced RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def ask_enhanced(self, 
                    question: str, 
                    search_method: str = "hybrid",
                    domain_filter: Optional[str] = None,
                    importance_filter: Optional[str] = None,
                    include_relationships: bool = True) -> Dict[str, Any]:
        """
        Enhanced ì§ˆë¬¸ ë‹µë³€ ìƒì„±
        
        Args:
            question: ì§ˆë¬¸
            search_method: ê²€ìƒ‰ ë°©ë²• (semantic, keyword, hybrid, smart)
            domain_filter: ë„ë©”ì¸ í•„í„° (ë°œì „ê³„íš, ê³„í†µìš´ì˜, ì „ë ¥ê±°ë˜, ì‹œì¥ìš´ì˜ ë“±)
            importance_filter: ì¤‘ìš”ë„ í•„í„° (critical, important, informational)
            include_relationships: ê´€ë ¨ ë¬¸ì„œ ì—°ê´€ì„± í¬í•¨ ì—¬ë¶€
            
        Returns:
            Enhanced ë‹µë³€ ê²°ê³¼
        """
        try:
            if not self.is_initialized:
                return {
                    "answer": "ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                    "confidence": 0.0,
                    "sources": [],
                    "error": "System not initialized"
                }
            
            self.logger.info(f"Enhanced ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: {question}")
            
            # 1. ë©”íƒ€ë°ì´í„° í•„í„°ë¥¼ í™œìš©í•œ ì •ë°€ ê²€ìƒ‰
            search_results = self.enhanced_vector_engine.search_with_metadata_filters(
                query=question,
                domain_filter=domain_filter,
                importance_filter=importance_filter,
                top_k=self.config["TOP_K"]
            )
            
            if not search_results:
                return {
                    "answer": "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "confidence": 0.0,
                    "sources": [],
                    "search_results": 0,
                    "filters_applied": {
                        "domain": domain_filter,
                        "importance": importance_filter
                    }
                }
            
            # 2. ì—°ê´€ ë¬¸ì„œ ì°¾ê¸° (ì˜µì…˜)
            related_docs = []
            if include_relationships and search_results:
                primary_doc_id = search_results[0].get("id")
                if primary_doc_id:
                    related_docs = self.relationship_mapper.get_related_documents(
                        document_id=primary_doc_id,
                        max_results=3
                    )
            
            # 3. ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ê³„ì¸µ ì •ë³´ í¬í•¨)
            enriched_context = self._create_enriched_context(search_results, related_docs)
            
            # 4. ë‹µë³€ ìƒì„±
            generation_result = self.answer_generator.generate_answer(
                context=enriched_context["text"],
                query=question,
                sources=enriched_context["sources"]
            )
            
            # 5. Enhanced ê²°ê³¼ êµ¬ì„±
            result = {
                "answer": generation_result.answer,
                "confidence": generation_result.confidence,
                "sources": generation_result.sources,
                "reasoning": generation_result.reasoning,
                "metadata": generation_result.metadata,
                
                # Enhanced ì •ë³´
                "search_results": len(search_results),
                "related_documents": len(related_docs),
                "filters_applied": {
                    "domain": domain_filter,
                    "importance": importance_filter
                },
                "enriched_context": {
                    "hierarchical_info": enriched_context["hierarchical_info"],
                    "domain_distribution": enriched_context["domain_distribution"],
                    "importance_levels": enriched_context["importance_levels"]
                },
                "search_method": search_method
            }
            
            self.logger.info(f"Enhanced ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ (ì‹ ë¢°ë„: {generation_result.confidence:.3f})")
            return result
            
        except Exception as e:
            self.logger.error(f"Enhanced ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "answer": "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "confidence": 0.0,
                "sources": [],
                "error": str(e)
            }
    
    def _create_enriched_context(self, search_results: List[Dict], related_docs: List[Dict]) -> Dict[str, Any]:
        """í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        
        # ê¸°ë³¸ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸
        context_parts = []
        sources = []
        hierarchical_info = []
        domain_distribution = {}
        importance_levels = {}
        
        # ì£¼ìš” ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
        for i, result in enumerate(search_results):
            text = result.get("text", "")
            metadata = result.get("metadata", {})
            
            # ê³„ì¸µ ì •ë³´ ì¶”ê°€
            hierarchy_path = metadata.get("full_path", "")
            hierarchy_title = metadata.get("hierarchy_title", "")
            
            if hierarchy_path or hierarchy_title:
                context_header = f"[{hierarchy_path or hierarchy_title}]"
                context_parts.append(f"{context_header}\n{text}")
                hierarchical_info.append({
                    "path": hierarchy_path,
                    "title": hierarchy_title,
                    "result_index": i
                })
            else:
                context_parts.append(text)
            
            # ë©”íƒ€ë°ì´í„° í†µê³„
            domain = metadata.get("market_domain", "ê¸°íƒ€")
            importance = metadata.get("importance_level", "informational")
            
            domain_distribution[domain] = domain_distribution.get(domain, 0) + 1
            importance_levels[importance] = importance_levels.get(importance, 0) + 1
            
            # ì†ŒìŠ¤ ì •ë³´
            source_info = metadata.get("source_file", "")
            if source_info:
                sources.append(source_info)
        
        # ê´€ë ¨ ë¬¸ì„œ ì¶”ê°€ (ê°„ëµí•˜ê²Œ)
        if related_docs:
            context_parts.append("\n[ê´€ë ¨ ë¬¸ì„œ ì •ë³´]")
            for rel_doc in related_docs[:2]:  # ìµœëŒ€ 2ê°œë§Œ
                rel_info = rel_doc.get("relationship", {})
                context_parts.append(f"- {rel_info.get('description', '')}")
        
        return {
            "text": "\n\n".join(context_parts),
            "sources": list(set(sources)),
            "hierarchical_info": hierarchical_info,
            "domain_distribution": domain_distribution,
            "importance_levels": importance_levels
        }
    
    def search_documents_enhanced(self, 
                                 query: str,
                                 method: str = "hybrid",
                                 domain_filter: Optional[str] = None,
                                 importance_filter: Optional[str] = None,
                                 regulation_filter: Optional[str] = None,
                                 top_k: int = 5) -> List[Dict[str, Any]]:
        """Enhanced ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            if not self.is_initialized:
                return []
            
            results = self.enhanced_vector_engine.search_with_metadata_filters(
                query=query,
                domain_filter=domain_filter,
                importance_filter=importance_filter,
                regulation_filter=regulation_filter,
                top_k=top_k
            )
            
            # ê²°ê³¼ë¥¼ ë” í’ë¶€í•œ ì •ë³´ë¡œ í™•ì¥
            enhanced_results = []
            for result in results:
                enhanced_result = result.copy()
                
                # ê´€ë ¨ ë¬¸ì„œ ì •ë³´ ì¶”ê°€
                doc_id = result.get("id")
                if doc_id:
                    related = self.relationship_mapper.get_related_documents(
                        document_id=doc_id,
                        max_results=3
                    )
                    enhanced_result["related_documents"] = related
                
                enhanced_results.append(enhanced_result)
            
            return enhanced_results
            
        except Exception as e:
            self.logger.error(f"Enhanced ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def get_domain_overview(self, domain: str) -> Dict[str, Any]:
        """íŠ¹ì • ë„ë©”ì¸ì— ëŒ€í•œ ê°œìš” ì •ë³´"""
        try:
            if not self.is_initialized:
                return {"error": "System not initialized"}
            
            # ë„ë©”ì¸ë³„ ë¬¸ì„œ ê²€ìƒ‰
            domain_docs = self.enhanced_vector_engine.search_with_metadata_filters(
                query=domain,
                domain_filter=domain,
                top_k=20
            )
            
            if not domain_docs:
                return {"error": f"ë„ë©”ì¸ '{domain}'ì— ëŒ€í•œ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
            
            # ë„ë©”ì¸ í†µê³„ ìƒì„±
            overview = {
                "domain": domain,
                "total_documents": len(domain_docs),
                "importance_distribution": {},
                "regulation_types": {},
                "key_topics": [],
                "representative_documents": []
            }
            
            # í†µê³„ ê³„ì‚°
            for doc in domain_docs:
                metadata = doc.get("metadata", {})
                
                importance = metadata.get("importance_level", "informational")
                regulation_type = metadata.get("regulation_type", "ê¸°íƒ€")
                
                overview["importance_distribution"][importance] = \
                    overview["importance_distribution"].get(importance, 0) + 1
                overview["regulation_types"][regulation_type] = \
                    overview["regulation_types"].get(regulation_type, 0) + 1
            
            # ëŒ€í‘œ ë¬¸ì„œ ì„ ë³„ (ë†’ì€ ì¤‘ìš”ë„ + ë†’ì€ ìœ ì‚¬ë„)
            representative = sorted(
                domain_docs[:10], 
                key=lambda x: (
                    1.0 if x.get("metadata", {}).get("importance_level") == "critical" else 0.5,
                    x.get("similarity", 0)
                ),
                reverse=True
            )[:5]
            
            overview["representative_documents"] = [
                {
                    "id": doc.get("id"),
                    "title": doc.get("metadata", {}).get("hierarchy_title", ""),
                    "similarity": doc.get("similarity", 0),
                    "importance": doc.get("metadata", {}).get("importance_level", "")
                }
                for doc in representative
            ]
            
            return overview
            
        except Exception as e:
            self.logger.error(f"ë„ë©”ì¸ ê°œìš” ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def get_enhanced_system_status(self) -> Dict[str, Any]:
        """Enhanced ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        try:
            status = {
                "initialized": self.is_initialized,
                "config": self.config,
                "timestamp": datetime.now().isoformat()
            }
            
            if self.is_initialized:
                # Enhanced Vector Engine í†µê³„
                if self.enhanced_vector_engine:
                    vector_stats = self.enhanced_vector_engine.get_statistics()
                    status["enhanced_vector_engine"] = vector_stats
                
                # Relationship Mapper í†µê³„
                if self.relationship_mapper:
                    relationship_stats = self.relationship_mapper.get_statistics()
                    status["relationship_mapper"] = relationship_stats
                
                # Document Hierarchy Analyzer í†µê³„
                if self.hierarchy_analyzer:
                    hierarchy_stats = self.hierarchy_analyzer.get_analysis_statistics()
                    status["hierarchy_analyzer"] = hierarchy_stats
            
            return status
            
        except Exception as e:
            self.logger.error(f"Enhanced ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def analyze_query_complexity(self, question: str) -> Dict[str, Any]:
        """ì§ˆë¬¸ ë³µì¡ë„ ë¶„ì„"""
        try:
            # ì§ˆë¬¸ ë¶„ì„
            analysis = {
                "question": question,
                "length": len(question),
                "word_count": len(question.split()),
                "complexity_indicators": {
                    "has_multiple_concepts": len([word for word in question.split() if word in 
                        ["ê·¸ë¦¬ê³ ", "ë˜í•œ", "ë°", "ì™€", "ê³¼", "ì—ì„œ", "ê´€ë ¨", "ì—°ê´€"]]) > 0,
                    "has_conditions": any(word in question for word in ["ë§Œì•½", "ê²½ìš°", "ë•Œ", "ì¡°ê±´"]),
                    "has_comparisons": any(word in question for word in ["ì°¨ì´", "ë¹„êµ", "ëŒ€ë¹„", "ë³´ë‹¤"]),
                    "has_procedures": any(word in question for word in ["ë°©ë²•", "ì ˆì°¨", "ê³¼ì •", "ë‹¨ê³„"]),
                    "has_temporal_aspects": any(word in question for word in ["ì–¸ì œ", "ì‹œê¸°", "ì´í›„", "ì´ì „", "ë™ì•ˆ"])
                },
                "recommended_search_strategy": "hybrid"
            }
            
            # ë³µì¡ë„ ê¸°ë°˜ ê²€ìƒ‰ ì „ëµ ì¶”ì²œ
            complexity_score = sum(analysis["complexity_indicators"].values())
            
            if complexity_score >= 3:
                analysis["recommended_search_strategy"] = "smart"
                analysis["recommended_filters"] = ["importance_filter:critical"]
            elif complexity_score >= 2:
                analysis["recommended_search_strategy"] = "hybrid"
                analysis["recommended_filters"] = ["domain_filter:ì¶”ì²œ"]
            else:
                analysis["recommended_search_strategy"] = "semantic"
                analysis["recommended_filters"] = []
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"ì§ˆë¬¸ ë³µì¡ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}


def setup_logging(log_level: str = "INFO", log_file: str = None):
    """ë¡œê¹… ì„¤ì •"""
    level = getattr(logging, log_level.upper(), logging.INFO)
    
    # ê¸°ë³¸ ë¡œê¹… ì„¤ì •
    handlers = [logging.StreamHandler()]
    
    if log_file:
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        handlers.append(logging.FileHandler(log_file, encoding='utf-8'))
    
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=handlers
    )


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ë°ëª¨ìš©)"""
    # ë¡œê¹… ì„¤ì •
    setup_logging("INFO", "logs/enhanced_rag_system.log")
    
    # Enhanced RAG ì‹œìŠ¤í…œ ìƒì„±
    enhanced_rag = EnhancedPowerMarketRAG()
    
    print("=== Enhanced ì „ë ¥ì‹œì¥ RAG ì‹œìŠ¤í…œ ===")
    print("1. ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    
    # ì´ˆê¸°í™”
    if enhanced_rag.initialize():
        print("âœ… Enhanced ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ìƒíƒœ í™•ì¸
        status = enhanced_rag.get_enhanced_system_status()
        print(f"ğŸ“Š Enhanced ì‹œìŠ¤í…œ ìƒíƒœ: ì •ìƒ")
        
        # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
        test_questions = [
            {
                "question": "í•˜ë£¨ì „ë°œì „ê³„íšì´ ë¬´ì—‡ì¸ê°€ìš”?",
                "domain_filter": "ë°œì „ê³„íš"
            },
            {
                "question": "ê³„í†µìš´ì˜ì˜ ê¸°ë³¸ ì›ì¹™ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "domain_filter": "ê³„í†µìš´ì˜",
                "importance_filter": "critical"
            },
            {
                "question": "ì „ë ¥ì‹œì¥ì—ì„œ ì˜ˆë¹„ë ¥ì˜ ì—­í• ê³¼ ì†¡ì „ì œì•½ì˜ ê´€ê³„ëŠ”?",
                "include_relationships": True
            }
        ]
        
        print("\n2. Enhanced í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì²˜ë¦¬:")
        for i, test in enumerate(test_questions, 1):
            question = test.pop("question")
            print(f"\n[ì§ˆë¬¸ {i}] {question}")
            
            # ì§ˆë¬¸ ë³µì¡ë„ ë¶„ì„
            complexity = enhanced_rag.analyze_query_complexity(question)
            print(f"ë³µì¡ë„: {sum(complexity['complexity_indicators'].values())}/5")
            
            # Enhanced ë‹µë³€ ìƒì„±
            result = enhanced_rag.ask_enhanced(question, **test)
            print(f"ë‹µë³€: {result['answer'][:150]}...")
            print(f"ì‹ ë¢°ë„: {result['confidence']:.3f}")
            print(f"ê²€ìƒ‰ ê²°ê³¼: {result['search_results']}ê°œ")
            if result.get('related_documents', 0) > 0:
                print(f"ê´€ë ¨ ë¬¸ì„œ: {result['related_documents']}ê°œ")
            
    else:
        print("âŒ Enhanced ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")


if __name__ == "__main__":
    main()